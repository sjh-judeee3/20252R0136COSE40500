import torch
import whisper
import os
from openai import OpenAI
from encoder import SLIPVideoEncoder 
from models import HybridTemporalModel
import sys # sys.stderr ì¶œë ¥ì„ ìœ„í•´ import
import numpy as np # ğŸ‘ˆ numpy.ndarray íƒ€ì…ì„ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.

# âš ï¸ API í‚¤ íŒŒì¼ì„ ì½ëŠ” í•¨ìˆ˜ ì •ì˜
def load_openai_api_key(filepath="openai.txt"):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            # íŒŒì¼ì˜ ì²« ë²ˆì§¸ ì¤„ì„ í‚¤ë¡œ ì‚¬ìš© (ì¤„ë°”ê¿ˆ ì œê±°)
            key = f.readline().strip()
            if not key:
                raise ValueError("API í‚¤ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return key
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: API í‚¤ íŒŒì¼ '{filepath}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        raise
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: API í‚¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
        raise
        
def print_error(message):
    """ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ sys.stderrë¡œ ì¶œë ¥í•˜ì—¬ Electron ì½˜ì†”ì— í‘œì‹œí•©ë‹ˆë‹¤."""
    print(message, file=sys.stderr)


class MultimodalAgent:
    def __init__(self, model_path, proto_path, device="cuda"):
        self.device = device
        
        # 1. ìˆ˜ì–´ ëª¨ë¸ ë¡œë“œ
        self.encoder = SLIPVideoEncoder(pretrained=False, embed_dim=512).to(device)
        self.temporal = HybridTemporalModel(input_dim=512, hidden_dim=512).to(device)
        
        try:
            checkpoint = torch.load(model_path, map_location=device)
            self.encoder.load_state_dict(checkpoint['encoder'])
            self.temporal.load_state_dict(checkpoint['temporal'])
        except FileNotFoundError:
            print_error(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ '{model_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            raise
        self.encoder.eval()
        self.temporal.eval()

        # 2. í”„ë¡œí† íƒ€ì…(ê¸°ì¤€ì ) ë¡œë“œ
        print_error("ğŸ“‚ ìˆ˜ì–´ ê¸°ì¤€ì (Prototype) ë¡œë”© ì¤‘...")
        try:
            # self.prototypesëŠ” ë¡œë“œëœ ë”•ì…”ë„ˆë¦¬ ì „ì²´
            data = torch.load(proto_path, map_location=device) 
        except FileNotFoundError:
            print_error(f"âŒ ì˜¤ë¥˜: í”„ë¡œí† íƒ€ì… íŒŒì¼ '{proto_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. make_prototypes.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            raise
        
        # ğŸš¨ğŸš¨ ìˆ˜ì •ëœ ë¶€ë¶„: ë¡œë“œëœ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ì— ë”°ë¼ í´ë˜ìŠ¤ ì´ë¦„ê³¼ í”„ë¡œí† íƒ€ì… ì¶”ì¶œ ğŸš¨ğŸš¨
        
        # 1) ë§Œì•½ íŒŒì¼ì´ {'classes': [ì´ë¦„ë“¤], 'prototypes': Tensor} êµ¬ì¡°ë¼ë©´:
        if isinstance(data, dict) and 'classes' in data and 'prototypes' in data:
            self.class_names = data['classes']
            self.proto_matrix = data['prototypes'].to(device)
            
            if not isinstance(self.proto_matrix, torch.Tensor):
                raise TypeError("ë¡œë”©ëœ 'prototypes' í‚¤ì˜ ê°’ì´ Tensorê°€ ì•„ë‹™ë‹ˆë‹¤.")
        
        # 2) ë§Œì•½ íŒŒì¼ì´ {í´ë˜ìŠ¤ì´ë¦„: í…ì„œ, í´ë˜ìŠ¤ì´ë¦„2: í…ì„œ, ...} í˜•íƒœë¼ë©´:
        else:
            self.prototypes = data # ë”•ì…”ë„ˆë¦¬ {ì´ë¦„: í…ì„œ}
            self.class_names = []
            proto_tensors = []
            
            for key, value in self.prototypes.items():
                # í…ì„œë‚˜ NumPy ë°°ì—´ë§Œ í•„í„°ë§í•˜ê³  ë¬¸ìì—´(str) ê°™ì€ ê²ƒì€ ë¬´ì‹œ
                if isinstance(value, torch.Tensor) or isinstance(value, np.ndarray):
                    self.class_names.append(key)
                    # í…ì„œê°€ ì•„ë‹ˆë©´ (NumPy ë°°ì—´ì´ë©´) ê°•ì œ ë³€í™˜
                    if not isinstance(value, torch.Tensor):
                        value = torch.tensor(value, dtype=torch.float32)
                    proto_tensors.append(value)
                else:
                    # 'str' ê°™ì€ ë¶ˆìˆœë¬¼ì€ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ê±´ë„ˆëœë‹ˆë‹¤.
                    print_error(f"âš ï¸ ê²½ê³ : í”„ë¡œí† íƒ€ì… ë”•ì…”ë„ˆë¦¬ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ê°’({key}: {type(value)})ì´ ë°œê²¬ë˜ì–´ ë¬´ì‹œí•©ë‹ˆë‹¤.")

            if not proto_tensors:
                 raise ValueError("í”„ë¡œí† íƒ€ì… ë”•ì…”ë„ˆë¦¬ì—ì„œ ìœ íš¨í•œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                 
            self.proto_matrix = torch.stack(proto_tensors).to(device)
            
        # -----------------------------------------------------------------------

        # 3. Whisper ë¡œë“œ
        print_error("ğŸ§ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘...")
        try:
            self.whisper = whisper.load_model("base").to(device)
        except Exception as e:
            print_error(f"âŒ ì˜¤ë¥˜: Whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ì—ëŸ¬: {e}")
            raise

        # 4. LLM í´ë¼ì´ì–¸íŠ¸ (OpenAI ì˜ˆì‹œ)
        # ğŸŒŸğŸŒŸğŸŒŸ ìˆ˜ì •ëœ ë¶€ë¶„: íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ ğŸŒŸğŸŒŸğŸŒŸ
        try:
            api_key = load_openai_api_key()
            self.client = OpenAI(api_key=api_key) 
        except Exception as e:
            print_error(f"âŒ ì˜¤ë¥˜: OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨. 'openai.txt' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”. ì—ëŸ¬: {e}")
            raise

    def predict_sign(self, video_tensor):
        """ì €ì¥ëœ í”„ë¡œí† íƒ€ì…ê³¼ ë¹„êµí•˜ì—¬ ê°€ì¥ ê°€ê¹Œìš´ ìˆ˜ì–´ ë‹¨ì–´ ì°¾ê¸°"""
        with torch.no_grad():
            video_tensor = video_tensor.to(self.device)
            features = self.encoder(video_tensor)
            query_emb = self.temporal(features) # (1, 512)

            # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚° (Euclidean Distance)
            dists = torch.cdist(query_emb, self.proto_matrix) # (1, Class_Num)
            
            # ê°€ì¥ ê±°ë¦¬ê°€ ì§§ì€ ì¸ë±ìŠ¤ ì°¾ê¸°
            min_dist_idx = torch.argmin(dists, dim=1).item()
            predicted_word = self.class_names[min_dist_idx]
            
            return predicted_word

    def generate_response(self, video_tensor, audio_path):
        # 1. ì¸ì‹ ìˆ˜í–‰
        sign_word = self.predict_sign(video_tensor)
        
        try:
            audio_result = self.whisper.transcribe(audio_path)['text']
        except Exception as e:
            print_error(f"âŒ ì˜¤ë¥˜: Whisper ìŒì„± ì¸ì‹ ì‹¤íŒ¨. ì—ëŸ¬: {e}")
            audio_result = "[ìŒì„± ì¸ì‹ ì‹¤íŒ¨]"
            
        print_error(f"\nğŸ‘€ ìˆ˜ì–´ ì¸ì‹: {sign_word}")
        print_error(f"ğŸ‘‚ ìŒì„± ì¸ì‹: {audio_result}")

        # 2. LLM í”„ë¡¬í”„íŠ¸ (Prompt Engineering)
        system_prompt = "ë‹¹ì‹ ì€ ì²­ê° ì¥ì• ì¸ê³¼ ë¹„ì¥ì• ì¸ì˜ ì†Œí†µì„ ë•ëŠ” ê³ ê¸‰ í†µì—­ AIì…ë‹ˆë‹¤.ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ë‹¨ìˆœ ë²ˆì—­ì´ ì•„ë‹ˆë¼, ìˆ˜ì–´ì™€ ìŒì„±ì´ë¼ëŠ” ë¶ˆì™„ì „í•œ ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì„ í†µí•© ì¶”ë¡ í•˜ì—¬ ì‚¬ìš©ìì˜ ì‹¤ì œ ì˜ë„ë¥¼ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ì—­í• ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤: 1. ìˆ˜ì–´ ë‹¨ì–´ì™€ ìŒì„± í…ìŠ¤íŠ¸ ê°ê°ì˜ ì˜ë¯¸ë¥¼ ë¶„ë¦¬ í•´ì„ 2. ë‘ ì •ë³´ ê°„ì˜ ë³´ì™„ ê´€ê³„ ë˜ëŠ” ì¶©ëŒ ì—¬ë¶€ íŒë‹¨ 3. ì‚¬ìš©ìì˜ ì˜ë„(ëª©ì , ëŒ€ìƒ, ìš”ì²­, ë°©í–¥ì„±)ë¥¼ ì¶”ë¡  4. ì¸ê°„ í†µì—­ì‚¬ê°€ ë§í•˜ë“¯ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ì¬êµ¬ì„±"
        
        user_prompt = f"""
        [ì…ë ¥ ì •ë³´]
        - ìˆ˜ì–´ ë‹¨ì–´: {sign_word}
        - ìŒì„± í…ìŠ¤íŠ¸: {audio_result}

        [ì¶”ë¡  ì§€ì¹¨]
        ì•„ë˜ ë‹¨ê³„ë¥¼ ìˆœì„œëŒ€ë¡œ ë‚´ë¶€ì ìœ¼ë¡œ ìˆ˜í–‰í•œ ë’¤, ìµœì¢… í•´ì„ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

        1ï¸âƒ£ ìˆ˜ì–´ ë‹¨ì–´ ë¶„ì„
        - ìˆ˜ì–´ ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚´ëŠ” í•µì‹¬ ê°œë…, í–‰ë™, ì¥ì†Œ, ê°ì •ì€ ë¬´ì—‡ì¸ê°€?

        2ï¸âƒ£ ìŒì„± í…ìŠ¤íŠ¸ ë¶„ì„
        - ìŒì„± í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ìš”ì²­, ìƒíƒœ, ëŒ€ìƒ, ë°©í–¥ í‘œí˜„ì€ ë¬´ì—‡ì¸ê°€?
        - ë¬¸ì¥ì´ ë¶ˆì™„ì „í•˜ë‹¤ë©´ ì–´ë–¤ ì •ë³´ê°€ ìƒëµë˜ì—ˆëŠ”ê°€?

        3ï¸âƒ£ í†µí•© ì¶”ë¡ 
        - ìˆ˜ì–´ì™€ ìŒì„±ì´ ì„œë¡œ ë³´ì™„í•˜ëŠ”ê°€, ì•„ë‹ˆë©´ í•˜ë‚˜ê°€ í•µì‹¬ì¸ê°€?
        - ì‚¬ìš©ìì˜ ìµœì¢… ëª©ì ì€ ë¬´ì—‡ì¸ê°€?
        - ì‚¬ìš©ìê°€ **ë¬´ì—‡ì„ ì›í•˜ê³ **, **ëˆ„êµ¬ì—ê²Œ**, **ì–´ë–¤ í–‰ë™ì„ ìš”ì²­**í•˜ëŠ”ê°€?

        4ï¸âƒ£ ë°©í–¥ ë° í™˜ê²½ ì¶”ë¡ 
        - ì†ì§“, ì§€ì‹œ ìˆ˜ì–´, ìŒì„± ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ë°©í–¥(ì™¼ìª½/ì˜¤ë¥¸ìª½/ì•/ë’¤/ìœ„/ì•„ë˜)ì„ ì¶”ë¡ 
        - ê°€ëŠ¥í•˜ë‹¤ë©´ ì£¼ë³€ í™˜ê²½(ì‚¬ë¬¼, ì¥ì†Œ, ìƒí™©)ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨

        5ï¸âƒ£ ìµœì¢… í•´ì„ ìƒì„±
        ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:

        "ì‚¬ìš©ìëŠ” (ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼)ë¥¼ í‘œí˜„í•˜ë©° (ìŒì„± ì¸ì‹ ê²°ê³¼)ë¼ê³  ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        ë˜í•œ (ë°©í–¥/í™˜ê²½ì— ëŒ€í•œ ì¶”ë¡ )ì„ ê³ ë ¤í•  ë•Œ,
        ì‚¬ìš©ìì˜ ì˜ë„ëŠ” (í†µí•©ëœ ì˜ë„ ë¬¸ì¥)ì…ë‹ˆë‹¤."

        """

        # 3. LLM í˜¸ì¶œ
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo", # ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print_error(f"âŒ ì˜¤ë¥˜: LLM API í˜¸ì¶œ ì‹¤íŒ¨. API í‚¤ ë˜ëŠ” ì¸í„°ë„· ì—°ê²° í™•ì¸ í•„ìš”. ì—ëŸ¬: {e}")
            return "âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨ (API ì˜¤ë¥˜)"


def main_run(model_path, proto_path, video_file, audio_file):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    print_error(f"ğŸš€ ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘... (Device: {device})")
    try:
        agent = MultimodalAgent(model_path, proto_path, device)
    except Exception as e:
        # ğŸš¨ ìˆ˜ì •: êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€(e)ë¥¼ ì¶œë ¥í•˜ë„ë¡ ë³€ê²½
        print_error(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤. ìƒì„¸ ì˜¤ë¥˜: {e}")
        return

    # 1. ë¹„ë””ì˜¤ í…ì„œ ë¡œë“œ
    print_error(f"ğŸ“‚ ë¹„ë””ì˜¤ í…ì„œ ë¡œë”© ì¤‘: {video_file}")
    try:
        video_tensor = torch.load(video_file, map_location=device).float()
    except Exception as e:
        print_error(f"âŒ ë¹„ë””ì˜¤ í…ì„œ ë¡œë“œ ì‹¤íŒ¨. íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—ëŸ¬: {e}")
        return
    
    # ğŸš¨ğŸš¨ ìˆ˜ì •: [T, C, H, W] í˜•íƒœë¥¼ [1, C, T, H, W] í˜•íƒœë¡œ ë³€í™˜ (Cì™€ T ìœ„ì¹˜ ë³€ê²½)
    if video_tensor.dim() == 4:
        # í˜„ì¬ í˜•íƒœê°€ (T, C, H, W)ë¼ë©´ -> (C, T, H, W)ë¡œ permute
        # ìº¡ì²˜ëœ í…ì„œì˜ ì°¨ì›ì´ (89, 3, 224, 224)ë¼ê³  ê°€ì •
        if video_tensor.size(1) == 3:
             # í˜•íƒœê°€ ì´ë¯¸ (T, C, H, W)ë¼ë©´, Cì™€ Të¥¼ ë°”ê¿” (C, T, H, W)ë¡œ ë§Œë“­ë‹ˆë‹¤.
             video_tensor = video_tensor.permute(1, 0, 2, 3) 
        
        # ìµœì¢…ì ìœ¼ë¡œ Batch ì°¨ì› (1)ì„ ì¶”ê°€í•˜ì—¬ (1, C, T, H, W)ë¡œ ë§Œë“­ë‹ˆë‹¤.
        video_tensor = video_tensor.unsqueeze(0) 

    # 2. ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ë° ì‘ë‹µ ìƒì„±
    print_error("ğŸ§  LLM ì‘ë‹µ ìƒì„± ì‹œì‘...")
    
    llm_response = agent.generate_response(video_tensor, audio_file)
    
    if "âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨" not in llm_response:
        # ì„±ê³µ ì‹œ: Electronì´ êµ¬ë…í•˜ëŠ” stdoutìœ¼ë¡œ ê²°ê³¼ ì „ë‹¬
        print(f"LLM_RESPONSE::{llm_response.strip()}")
        sys.stdout.flush()
    else:
        # ì‹¤íŒ¨ ì‹œ: stderrë¡œ ì•Œë¦¼
        print_error("âŒ ìµœì¢… ì¶œë ¥ ì‹¤íŒ¨.")
        
    print_error("="*50 + "\n")
    return llm_response


if __name__ == '__main__':
    # âš ï¸ ìº¡ì²˜ íŒŒì¼ ê²½ë¡œê°€ motionCapture.pyì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
    MODEL_PATH = "slip_protonet_final.pth" 
    PROTO_PATH = "prototypes.pt"
    VIDEO_FILE = "captured_video.pt" 
    AUDIO_FILE = "captured_audio.wav"
    
    if os.path.exists(VIDEO_FILE) and os.path.exists(AUDIO_FILE):
        main_run(MODEL_PATH, PROTO_PATH, VIDEO_FILE, AUDIO_FILE)
    else:
        print_error(f"âš ï¸ {VIDEO_FILE} ë˜ëŠ” {AUDIO_FILE} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print_error("motionCapture.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ìˆ˜ì–´ ë™ì‘ê³¼ ìŒì„±ì„ ìº¡ì²˜í•´ì£¼ì„¸ìš”.")
